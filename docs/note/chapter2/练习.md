# 练习

***

证明分布$p(\theta)$的均值最小化绝对误差损失函数的期望值为中位数：
$$
E[|\theta-a|] = \int|\theta-a|p(\theta)d\theta
$$
证明：
$$
\begin{aligned}
E[|\theta-a|] &= \int|\theta-a|p(\theta)d\theta\\
&= \int_{-\infty}^a(a-\theta)p(\theta)d\theta + \int_a^{+\infty}(\theta-a)p(\theta)d\theta\\
&= a\int_{-\infty}^ap(\theta)d\theta - \int_{-\infty}^a\theta p(\theta)d\theta -a\int_{a}^{+\infty}p(\theta)d\theta + \int_{a}^{+\infty}\theta p(\theta)d\theta
\end{aligned}
$$
对其求导，得
$$
\begin{aligned}
(E[|\theta-a|])^{\prime} &= ap(a) + \int_{-\infty}^ap(\theta)d\theta - ap(a) - \int_a^{+\infty}p(\theta)d\theta + ap(a)-ap(a)\\
&= \int_{-\infty}^ap(\theta)d\theta - \int_a^{+\infty}p(\theta)d\theta
\end{aligned}
$$
因此当
$$
\int_{-\infty}^ap(\theta)d\theta = \int_a^{+\infty}p(\theta)d\theta
$$
时取得最小值。

所以当取中位数时达到最小值。

***

找出使下列损失函数期望值最小得最优点估计$a$
$$
C(\theta,a) = (\theta-a)^T\mathbf{R}(\theta-a)
$$
其中$\mathbf{R}$为正定矩阵，并且参数的分布为$\theta\sim p(\theta|y_{1:T})$。

解：

对上述函数进行展开
$$
\begin{aligned}
C(\theta,a) &= \theta^T\mathbf{R}\theta - \theta^T\mathbf{R}a + a^T\mathbf{R}a-a^T\mathbf{R}\theta\\
\end{aligned}
$$
对其进行求导，得：
$$
(C(\theta,a))^{\prime} = -\mathbf{R}^T\theta + (\mathbf{R}+\mathbf{R}^T)a - \mathbf{R}\theta
$$
其期望损失函数为
$$
\int (\theta^T\mathbf{R}\theta - \theta^T\mathbf{R}a + a^T\mathbf{R}a-a^T\mathbf{R}\theta)p(\theta)d\theta
$$
对其进行求导，得
$$
\int(-\mathbf{R}^T\theta + (\mathbf{R}+\mathbf{R}^T)a - \mathbf{R}\theta)p(\theta)d\theta
$$
所以得
$$
a = \int \theta p(\theta)d\theta
$$


***

假设我们从线性回归模型中得到$T$个观测结果对$(x_k,y_k)$：
$$
y_k = \theta_1x_k + \theta_2, \quad k=1,2,\cdots,T.
$$
我们得目的是推导参数$\theta_1$和$\theta_2$的估计使得下面的误差可以最小化(最小二乘法)：
$$
E(\theta_1,\theta_2) = \sum_{k=1}^T(y_k-\theta_1x_k-\theta_2)^2
$$

+ 定义$y=(y_1,\cdots,y_T)^T$和$\theta=(\theta_1\quad\theta_2)$。证明线性模型公式可以被写为
  $$
  y = X\theta
  $$

+ 写下上述损失函数的矩阵行驶，利用$y,X,\theta$

+ 计算矩阵形式的误差函数的梯度并通常找到梯度为零的点来解决最小二乘法

解：

问题一显然成立。

问题二：
$$
E(\theta)  = (y-X\theta)^T(y-X\theta)
$$
问题三：

对问题二得到的式子进行求导，得：
$$
\theta = (X^TX)^{-1}(X^Ty)
$$

***

假设在线性模型中我们对参数$\theta_1,\theta_2$设置如下的独立高斯先验：
$$
\begin{aligned}
\theta_1&\sim N(0,\sigma^2)\\
\theta_2&\sim N(0,\sigma^2)
\end{aligned}
$$
其中方差$\sigma^2$是已知的。观测$y_k$建模为
$$
y_k = \theta_1x_k + \theta_2 + \varepsilon_k,\quad k = 1,2,\cdots,T.
$$
其中$\varepsilon_k$为均值为零方差为一的独立高斯误差，即$\varepsilon_k\sim N(0,1)$。值$x_k$是固定和已知的。后验分布可以写为
$$
p(\theta|y_1,\cdots,y_T)\propto \exp\left(-\frac{1}{2}\sum_{k=1}^T(y_k-\theta_1x_k-\theta_2)^2\right)\exp(-\frac{1}{2\sigma^2}\theta_1^2)\exp(-\frac{1}{2\sigma^2}\theta_2^2)
$$

+ 将上述后验分布写为矩阵形式
+ 因为高斯分布总是分布对称的，所以它的平均值$m$是分布的最大值。通过计算指数的梯度并找出它消失的位置，找出后验均值。
+ 通过计算指数的二阶导数矩阵$H$，求出分布的协方差。后验协方差为$P = -H^{-1}$(为什么？)
+ 由此产生的后验分布是什么。与上一题的最小二乘估计有什么关系？

解：

问题一的矩阵形式：
$$
\exp(\frac{(y-X\theta)^T(y-X\theta)}{2} + \frac{\theta^T\theta}{2\sigma^2})
$$
问题二：

对问题一进行求导：
$$
-(\frac{(E+E^T)}{2\sigma^2}\theta + X^TX\theta - X^Ty)(\exp(-\frac{(y-X\theta)^T(y-X\theta)}{2} - \frac{\theta^T\theta}{2\sigma^2}))
$$
即
$$
\theta = (X^TX+\frac{E}{\sigma^2})^{-1}(X^Ty)
$$
其中$E$为单位矩阵。

问题三：

指数的海森矩阵$H$为
$$
H = -(X^TX+\frac{E}{\sigma^2})
$$
我们将$H^{-1}$作为协方差带入发现与原式相等，所以$P = -H^{-1}$。

问题四

产生的后验分布也为高斯分布。其结果相当于是有正则化项的最小二乘法。

***

对上一个练习中的贝叶斯线性回归问题实施基于重要性采样的近似。使用合适的高斯分布作为参数$\theta$的重要性分布。检验后验均值和协方差是否与上一个练习中计算的精确值一致。

~~~matlab
% 我还没搞懂重要性采样，等弄懂了再来填坑
~~~









