# 数值方法

一旦建立的模型规范，原则上贝叶斯推理提供了计算任何模型后验分布和点估计的方程。然而，实际的困难是，方程中涉及的积分运算很少以解析的方式进行，需要数值方法。

+ 高斯近似非常普遍，其后验分布用高斯分布近似
  $$
  p(\theta|y_{1:T})\simeq N(\theta|m,P)
  $$
  高斯近似的均值$m$和协方差$P$可以通过匹配后验分布的前两个矩或者利用后验分布的众数来近似$m$，利用在众数处的后验分布的曲率来近似$P$来计算。注意，我们引入了符号$\simeq$，这里的意思是假设左侧与右侧大致相等。

+ 如果积分的维数适中，也可以使用多维求积或立方积分方法，如`Gauss-Hermite`求积。其思想是去确定地形成一组具有代表性的样本点$\{\theta^{(i)}:i=1,\cdots,N\}$(有时也被称为`sigma points`)并且形成积分作为加权平均的近似值：
  $$
  E[g(\theta)|y_{1:T}] \approx \sum_{i=1}^NW_ig(\theta^{(i)})
  $$
  其中权重$W_i$的数值由算法决定。

+ 在直接蒙特卡洛算法(Monte Carlo methods)中随机从后验分布中选择一组$N$个样本
  $$
  \theta^{(i)}\sim p(\theta|y_{1:T}),\quad i = 1,\cdots,N
  $$
  并且函数$g(\cdot)$的期望可以用样本平均来近似：
  $$
  E[g(\theta)|y_{1:T}]\approx \frac{1}{N}\sum_ig(\theta^{(i)})
  $$
  这种方法的另一种解释是蒙特卡洛方法形成后验密度的近似值：
  $$
  p(\theta|y_{1:T})\approx \frac{1}{N}\sum_{i=1}^N\delta(\theta-\theta^{(i)})
  $$
  其中$\delta(\cdot)$是迪利克雷函数。蒙特卡洛逼近的收敛性由中心极限定律保证，并且误差项至少在理论上是在某些理想条件下与$\theta$的维数无关的。

+ 生成蒙特卡罗样本的有效方法是马尔可夫链蒙特卡罗(MCMC)方法。在MCMC方法中，构造一个马尔可夫链，使其以目标分布作为其平稳分布。通过模拟马尔可夫链，可以从目标分布中产生样本。

+ 重要性采样是用于从目标分布生成加权样本的简单算法。与直接蒙特卡洛采样和MCMC的不同在于其每个粒子都有与之相关的权重，修正了真实目标分布和从中提取样本的近似重要性分布$\pi(\cdot)$之间的差异。

  通过从重要性分布中采$N$个样本可以形成重要性估计
  $$
  \theta^{(i)}\sim \pi(\theta|y_{1:T}),\quad i = 1,\cdots,N
  $$
  重要性权重计算为
  $$
  \tilde{w}^{(i)} = \frac{1}{N}\frac{p(\theta^{(i)}|y_{1:T})}{\pi(\theta^{(i)}|y_{1:T})}
  $$
  则任何函数$g(\cdot)$的期望可以近似为
  $$
  E[g(\theta)|y_{1:T}]\approx \sum_{i=1}^N\tilde{w}^{(i)}g(\theta^{(i)})
  $$
  或者
  $$
  \mathrm{E}\left[\mathbf{g}(\boldsymbol{\theta}) \mid \mathbf{y}_{1: T}\right] \approx \frac{\sum_{i=1}^{N} \tilde{w}^{(i)} \mathbf{g}\left(\boldsymbol{\theta}^{(i)}\right)}{\sum_{i=1}^{N} \tilde{w}^{(i)}}
  $$

